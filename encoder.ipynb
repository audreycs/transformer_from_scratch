{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Encoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Input Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Create input sequence and input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_seq = ['<sos>', 'hello', 'world', '<eos>']\n",
    "input_tokens = [132, 87, 101, 777] # just for example, in practice, there is a tokenizer to convert the input sequence to tokens\n",
    "\n",
    "# imagine we have a vocabulary of 1000 words\n",
    "vocab_size = 1000\n",
    "embedding_dim = 64\n",
    "\n",
    "vocab_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# create input embeddings\n",
    "input_embeddings = vocab_embedding_table(torch.LongTensor(input_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Create positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "max_seq_len = len(input_seq)\n",
    "positional_encodings = torch.zeros(max_seq_len, embedding_dim)\n",
    "\n",
    "for i in range(max_seq_len):\n",
    "    for j in range(embedding_dim):\n",
    "        if j % 2 == 0:\n",
    "            positional_encodings[i, j] = math.sin(i / (10000 ** (j / embedding_dim)))\n",
    "        else:\n",
    "            positional_encodings[i, j] = math.cos(i / (10000 ** ((j - 1) / embedding_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Add input embeddings and positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = input_embeddings + positional_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Multi-head Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Create query, key, value matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64]) torch.Size([4, 64]) torch.Size([4, 64])\n"
     ]
    }
   ],
   "source": [
    "W_q = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "W_k = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "W_v = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "\n",
    "Q = W_q(input_embeddings)\n",
    "K = W_k(input_embeddings)\n",
    "V = W_v(input_embeddings)\n",
    "\n",
    "print(Q.shape, K.shape, V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Convert To Multi-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32]) torch.Size([2, 4, 32]) torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "head_num = 2\n",
    "Q = Q.view(head_num, len(input_seq), embedding_dim//head_num)\n",
    "K = K.view(head_num, len(input_seq), embedding_dim//head_num)\n",
    "V = V.view(head_num, len(input_seq), embedding_dim//head_num)\n",
    "\n",
    "print(Q.shape, K.shape, V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Calculate Attentions\n",
    "This include matrix multiplication, scaling, and softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "QK = torch.matmul(Q, K.transpose(1, 2))\n",
    "\n",
    "# scaling\n",
    "QK = QK / math.sqrt(embedding_dim//head_num)\n",
    "\n",
    "# softmax\n",
    "QK = torch.softmax(QK, dim=-1)\n",
    "\n",
    "print(QK.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Multiply Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "QKV = torch.matmul(QK, V)\n",
    "\n",
    "print(QKV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_output = QKV.transpose(0, 1).contiguous()\n",
    "multi_head_output = multi_head_output.view(len(input_seq), embedding_dim)\n",
    "\n",
    "# residual connection\n",
    "output = input_embeddings + multi_head_output\n",
    "\n",
    "# layer normalization\n",
    "output = nn.LayerNorm(embedding_dim)(output)\n",
    "output = nn.Dropout(0.3)(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 FeedForward Layer (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ff_1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "W_ff_2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "# feedforward: linear -> relu -> linear\n",
    "ff_output = W_ff_1(output)\n",
    "ff_output = nn.ReLU()(ff_output)\n",
    "ff_output = W_ff_2(ff_output)\n",
    "\n",
    "# residual connection\n",
    "ff_output = output + ff_output\n",
    "\n",
    "# layer normalization\n",
    "ff_output = nn.LayerNorm(embedding_dim)(ff_output)\n",
    "ff_output = nn.Dropout(0.3)(ff_output)\n",
    "\n",
    "encoder_output = ff_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
